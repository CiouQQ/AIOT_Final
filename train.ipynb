{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ea49159b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------Generate Datasets-----------------\n",
      "-------------Save Datasets-----------------\n",
      "241\n",
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n",
      "training...\n",
      "ok\n",
      "testing...\n",
      "0.9253112033195021\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.datasets import mnist\n",
    "from keras import utils\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "train_path = './AIOT/'    \n",
    "train_txt = './label.txt'  \n",
    "x_train_savepath = './mnist_x_train.npy'   \n",
    "y_train_savepath = './mnist_y_train.npy'   \n",
    "\n",
    "test_path = './AIOT/'     \n",
    "test_txt = './label.txt'   \n",
    "x_test_savepath = './mnist_x_test.npy'     \n",
    "y_test_savepath = './mnist_y_test.npy'     \n",
    "\n",
    "\n",
    "def generateds(path, txt):      \n",
    "    f = open(txt, 'r')          \n",
    "    contents = f.readlines()    \n",
    "    f.close()                   \n",
    "    x, y_ = [], []              \n",
    "    for content in contents:   \n",
    "        value = content.split()           \n",
    "        img_path = path + value[0]        \n",
    "        img = Image.open(img_path)        \n",
    "        img = np.array(img.convert('L'))  \n",
    "        img = img / 255.                  \n",
    "        x.append(img)                     \n",
    "        y_.append(value[1])               \n",
    "    \n",
    "\n",
    "    x = np.array(x)          \n",
    "    y_ = np.array(y_)         \n",
    "    y_ = y_.astype(np.int64)  \n",
    "    return x, y_             \n",
    "\n",
    "if os.path.exists(x_train_savepath) and os.path.exists(y_train_savepath) and os.path.exists(\n",
    "        x_test_savepath) and os.path.exists(y_test_savepath):  \n",
    "    print('-------------Load Datasets-----------------')\n",
    "    x_train_save = np.load(x_train_savepath)\n",
    "    y_train = np.load(y_train_savepath)\n",
    "    x_test_save = np.load(x_test_savepath)\n",
    "    y_test = np.load(y_test_savepath)\n",
    "    x_train = np.reshape(x_train_save, (len(x_train_save), 28, 28))  \n",
    "    x_test = np.reshape(x_test_save, (len(x_test_save), 28, 28))    \n",
    "else:  \n",
    "    print('-------------Generate Datasets-----------------')\n",
    "    x_train, y_train = generateds(train_path, train_txt)\n",
    "    x_test, y_test = generateds(test_path, test_txt)\n",
    "    print('-------------Save Datasets-----------------')\n",
    "    x_train_save = np.reshape(x_train, (len(x_train), -1))\n",
    "    x_test_save = np.reshape(x_test, (len(x_test), -1))\n",
    "    np.save(x_train_savepath, x_train_save)\n",
    "    np.save(y_train_savepath, y_train)\n",
    "    np.save(x_test_savepath, x_test_save)\n",
    "    np.save(y_test_savepath, y_test)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# (x_train, y_train), (x_test, y_test) = mnist.load_data()  # 載入訓練集\n",
    "\n",
    "# 訓練集資料\n",
    "print(x_train.shape[0])\n",
    "x_train = x_train.reshape(x_train.shape[0],-1)  # 轉換資料形狀\n",
    "x_train = x_train.astype('float32')/255         # 轉換資料型別\n",
    "y_train = y_train.astype(np.float32)\n",
    "print(type(x_train))\n",
    "print(type(y_train))\n",
    "\n",
    "# 測試集資料\n",
    "x_test = x_test.reshape(x_test.shape[0],-1)     # 轉換資料形狀\n",
    "x_test = x_test.astype('float32')/255           # 轉換資料型別\n",
    "y_test = y_test.astype(np.float32)\n",
    "\n",
    "knn=cv2.ml.KNearest_create()                    # 建立 KNN 訓練方法\n",
    "knn.setDefaultK(5)                              # 參數設定\n",
    "knn.setIsClassifier(True)\n",
    "\n",
    "print('training...')\n",
    "knn.train(x_train, cv2.ml.ROW_SAMPLE, y_train)  # 開始訓練\n",
    "knn.save('mnist_knn_test.xml')                       # 儲存訓練模型\n",
    "print('ok')\n",
    "\n",
    "print('testing...')\n",
    "test_pre = knn.predict(x_test)                  # 讀取測試集並進行辨識\n",
    "test_ret = test_pre[1]\n",
    "test_ret = test_ret.reshape(-1,)\n",
    "test_sum = (test_ret == y_test)\n",
    "acc = test_sum.mean()                           # 得到準確率\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2abad0c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
